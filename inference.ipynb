{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c34d4-d37a-4237-8535-8bdddbe946f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T07:20:14.671724Z",
     "iopub.status.busy": "2025-05-02T07:20:14.670822Z",
     "iopub.status.idle": "2025-05-02T07:34:06.966618Z",
     "shell.execute_reply": "2025-05-02T07:34:06.964964Z",
     "shell.execute_reply.started": "2025-05-02T07:20:14.671665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-05-02 07:21:58.960976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746170519.456890   21679 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746170519.613241   21679 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746170521.104349   21679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746170521.104392   21679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746170521.104396   21679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746170521.104399   21679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 07:22:01.193956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [10:22<00:00, 62.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "model_name = \"mistralai/Mistral-Small-24B-Instruct-2501\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=quant_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2eb0d",
   "metadata": {},
   "source": [
    "Loading QLoRA checkpoint and adding adapters for the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ab380e-7a8c-4e0e-9262-40f9841de86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T07:34:44.033752Z",
     "iopub.status.busy": "2025-05-02T07:34:44.032787Z",
     "iopub.status.idle": "2025-05-02T07:34:49.103868Z",
     "shell.execute_reply": "2025-05-02T07:34:49.102144Z",
     "shell.execute_reply.started": "2025-05-02T07:34:44.033707Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "merged_model = PeftModel.from_pretrained(model, \"./mistral-24b-clm-qlora/checkpoint-1796\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f1f107-64c7-441b-9151-2e1381d89d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T07:34:54.901762Z",
     "iopub.status.busy": "2025-05-02T07:34:54.901005Z",
     "iopub.status.idle": "2025-05-02T07:34:54.923019Z",
     "shell.execute_reply": "2025-05-02T07:34:54.921346Z",
     "shell.execute_reply.started": "2025-05-02T07:34:54.901711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Ты — полезный и вежливый помощник ассистент-диетолог, который отвечает кратко и по делу.\"\n",
    "user_prompt = \"как приготовить фарш для макарон по-флотски?\"\n",
    "\n",
    "full_prompt = f\"<s>[SYSTEM] {system_prompt} [/SYSTEM]\\n[USER] {user_prompt} [/USER]\\n[ASSISTANT]\"\n",
    "input_ids = tokenizer.encode(full_prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d82495db-7d77-477b-a620-adc2c3461108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T07:50:49.451748Z",
     "iopub.status.busy": "2025-05-02T07:50:49.450863Z",
     "iopub.status.idle": "2025-05-02T07:51:06.666647Z",
     "shell.execute_reply": "2025-05-02T07:51:06.665264Z",
     "shell.execute_reply.started": "2025-05-02T07:50:49.451703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = merged_model.generate(\n",
    "        input_ids,\n",
    "        max_length=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2794ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователь: как приготовить фарш для макарон по-флотски? \n",
      "Ассистент: Для приготовления фарша для макарон по-флотски вам потребуется:\n",
      "- фарш (говяжий, свиной или смешанный) — 400 г\n",
      "- лук — 1 шт\n",
      "- морковь — 1 шт\n",
      "- томатная паста — 2 ст. л. - соль, перец, специи (паприка, чеснок) — по вкусу\n",
      "- растительное масло — для жарки\n",
      "- макароны — 400 г\n",
      "- вода — для варки макарон\n",
      "- сливочное масло — 1 ст. л. - петрушка — для украшения\n",
      "Приготовление:\n",
      "1. Мелко нарежьте лук и морковь. Обжарьте их на растительном масле до золотистого цвета. 2. Добавьте фарш, обжарьте до готовности, постоянно помешивая. 3. Добавьте томатную пасту, соль, перец и специи. Тушите фарш еще 5 минут. 4. Отварите макароны в подсоленной воде до готовности. 5. Смешайте макароны с фаршем, добавьте сливочное масло. 6. Подавайте, украсив петрушкой. Приятного аппетита! \n",
      "При необходимости, можно добавить немного воды из-под макарон, чтобы соус был более жидким.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "match = re.search(r\"\\[ASSISTANT\\](.*?)\\[/ASSISTANT\\]\", generated_text, re.DOTALL)\n",
    "if match:\n",
    "    assistant_text = match.group(1).strip()\n",
    "\n",
    "answer = f'Пользователь: {user_prompt} \\nАссистент: {assistant_text}'\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68483cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
